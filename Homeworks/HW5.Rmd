---
title: "Homework 5"
author: "Francis Olakangil"
date: "2023-11-01"
output: html_document
---

1. (30pts) Write ONE paragraph discussing the issues arising from any of these scenarios (pick one option):

(a) In 2006, AOL released a database of search terms that users had used in the prior month (see [https://www.nytimes.com/2006/08/09/technology/09aol.html](https://www.nytimes.com/2006/08/09/technology/09aol.html)). Research this disclosure and the reaction that ensued. What ethical issues are involved? What potential impact has this disclosure had?

(b) A Slate article [https://slate.com/technology/2016/02/how-to-bring-better-ethics-to-data-science.html](https://slate.com/technology/2016/02/how-to-bring-better-ethics-to-data-science.html) discussed whether race/ethnicity should be included in a predictive model for how long
a homeless family would stay in homeless services. Discuss the ethical considerations involved in whether race/ethnicity should be included
as a predictor in the model.

(c) A company uses a machine-learning algorithm to determine which job advertisement to display for users searching for technology jobs.
Based on past results, the algorithm tends to display lower-paying jobs for women than for men (after controlling for other characteris-
tics than gender). What ethical considerations might be considered when reviewing this algorithm?

ANSWER (prompt a): In 2006, AOL, an online service provider, released a huge database of thousands of users' search queries entered into the search engine. Ranging from internet research into various diseases to researching how to kill oneself, it seems that thousands of users' search entries were made public. The resulting reaction from such a release of private data caused an uproar in the public community, where the NYT article specifically depicts an interview with an elderly woman whose identity was stolen because of the release. The main reaction that resulted from the release was not only comprised of outcry, but also of desperate questioning of how powerful search engine companies really are in terms of their data collection. Particularly, ethical issues such as the violation of privacy and identity theft became hot topics after AOL's release. This was primarily because so much data about individuals' search queries were released that interent bloggers and online programmers were able to trace enough information to the true identity of these users. Although AOL was well-intentioned in the release, wanting to help academic researchers, it instead led to questions about tracking various users, focused advertising, etc. The disclosure has ultimately impacted how both the government and the citizen view these search engines and respective companies. Having dubbed it a "ticking privacy time bomb," AOL's disclosure has highlighted how important it is to be cognizant of data-tracking and how much of one's own identity is given up by using these search engines. Whether it be "betraying intimate emotions and personal dilemmas" or raising questions about what data can and cannot be tracked from a security perspective, AOL's data release is an important milestone in understanding just how small of an amount of data of each individual is truly under their control.

2. (30pts) stringr Problems

(a) In the palmerpenguins dataset, create a new column that combines the species and island names into a single string with a hyphen (-) in between. For example, if the species is "Adelie" and the island is "Torgersen," the new column should contain "Adelie-Torgersen."

```{r}
library(tidyverse)
library(dplyr)
options(repos = c(CRAN = "https://mirrors.ku.edu/cran/")) #credit to stackoverflow for helping me with error of not finding cran mirror
install.packages("stringr")
install.packages("palmerpenguins")
library(palmerpenguins)
data(penguins)
#View(penguins)

name_combo <- penguins %>% 
  mutate(speciesIsland = paste(species, island, sep = "-"))
#paste concatenates the values in the species and island columns, with a hyphen separating the values
glimpse(name_combo)

```

(b) Find and count the penguins whose species names start with the letter "G" in the palmerpenguins dataset.
```{r}
g_species <- penguins %>% 
  filter(str_detect(species, "^G")) %>% 
  summarise(count = n())
g_species

#the caret symbol before the G in quotes denotes that the str_detect function needs to go to the species column and search for elements that start with char G

print(g_species)

```
(c) Using the flights dataset, create a new column that combines the year and month columns into a Date class column. For instance, if the year is 2019 and the month is 3, the new column should contain "2019-03-01."
```{r}
library(tidyverse)
library(nycflights13)
library(dplyr)
data("flights")
data("planes")
#view(planes)
view(flights)


#flights dataset, in comparison to planes one, has both year and month columns
#third parameter of paste function is 01 because instructions don't specify to use actual day column
year_month <- flights %>% 
  mutate(date_class = as.Date(paste(year, month, "01", sep = "-")))
glimpse(year_month)

#would rather use planes dataset just because it has other years apart from 2013, but it has no month column, so didn't use it.

```

(d) From the flights dataset and planes dataset, combine them and then filter the rows where the plane is from 2000-2010 and the flight month is either March (3), May (5), or September (9).
```{r}
planes_dataset <- planes
#sets planes dataset into usable variable
combination <- flights %>% 
  inner_join(planes_dataset, by = "tailnum")
combination
#using inner_join to combine both datasets based on common criteria of tailnum

filtering <- combination %>% 
  filter(year.y >= 2000 & year.y <= 2010 & month %in% c(3,5,9))
  #after viewing the combined dataset, two year columns were created since each dataset had their     own, thus using year.y, which is the year column from the planes dataset. 


#filtering combined dataset based on specified conditions, %in% is conditioning whether month values fit the elements in specified vector

#NOTE: in the print, year.x is shown first which is the year column from the first dataset and not the one being used for the purposes of this question. If wanting to verify if the filter was done correctly, horizontally scroll print output to view the outputted year.y
print(filtering)

```

(e) In the palmerpenguins dataset, create a new column that includes the penguin's name (penguinid) and the year they were recorded. For instance, if a penguin's name is "Nelson" and the year is 2007, the new column should contain "Nelson-2007." Then, use this new column to filter and count penguins whose names contain "Adelie" and were recorded in the year 2007.
```{r}
#view(penguins_raw)

#INSTRUCTIONS amendment from Campuswire: species and year combined to make penguin ID.

penguinid <- penguins %>% 
  mutate(name_species = paste(species, year, sep = "-")) %>% 
  filter(grepl("Adelie", name_species) & year == 2007) %>%
  nrow()
penguinid

#grepl() fxn is used as a comparison function to see whether the string portion of a specified row contains "adelie"

```

3. (40pts) map Problems

(a) (15pts) Using the dataset `airquality` in base R, find how many missing values are in each column function `map` (ONLY using `map`).
```{r}
data(airquality)
#view(airquality)
library(purrr) #cred to stackoverflow for showing me this package

#creates fxn to count number of missing values across columns and insert into vector
values_missing <- function(x) sum(is.na(x))
missing <- map(airquality, values_missing)

# Creates df with two columns to categorize outputs.
values_df <- data.frame(Category = names(airquality), Missing_Vals = missing)

print(values_df)

```

(b) (25pts) Using the following code to create two dataframes `dat1` and `dat2`. Then find the *sum* of the differences columnwise between the two datasets using `map2()`. This will give you a list output, print that out and then find the sum of those values. This will be the overall difference
```{r}
dat1 <- data.frame(matrix(rnorm(2000, 3, 1), ncol = 10))
dat2 <- data.frame(matrix(rnorm(2000, 3, 1), ncol = 10))
library(purrr)

sum_diff <- map2(dat1, dat2, ~ sum(.x - .y))
#this subtracts the corresponding values of the two dfs and then adds them, hence sum()
print(sum_diff)

overallsum_diff <- reduce(sum_diff, `+`)
#the reduce fxn combines the elements of the sum_diff list, + operator combines
print(overallsum_diff)
      
```
